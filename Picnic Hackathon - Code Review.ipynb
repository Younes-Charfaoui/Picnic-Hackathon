{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Picnic Hackathon - Code.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RSzuFesrTWwk","colab_type":"text"},"source":["## **This is the Code from the Winner of Picnic Hackathon's Winner**\n","\n","Note: The goal this week is to go through the code, and get understanding of the work done here. Then we can meet up and discuss a plan of action to create a model ourselves. - Yuvraj"]},{"cell_type":"markdown","metadata":{"id":"j1vfxwkgUZqA","colab_type":"text"},"source":["**LIBRARIES**"]},{"cell_type":"code","metadata":{"id":"0HuHHZMbUR7b","colab_type":"code","colab":{}},"source":["# Data Science Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# %matplotlib inline\n","\n","# Fastai Library\n","import fastai\n","from fastai.vision import *\n","from fastai.vision.models import *\n","import torch\n","\n","# Others\n","from pathlib import Path\n","import glob\n","from PIL import ImageFile\n","from google.colab import drive\n","import re\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A0scwkocUeux","colab_type":"text"},"source":["**DATA PREPROCESSING**"]},{"cell_type":"code","metadata":{"id":"1RQmBfD0Uhzl","colab_type":"code","colab":{}},"source":["# making some settings.\n","np.random.seed(42)\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","# Accessing The Data via Google Drive.\n","drive.mount('/content/gdrive')\n","\n","# Make sure to setup the path to yours.\n","path_to_folder = 'gdrive/My Drive/Dataset/The Picnic Hackathon 2019/'\n","train_df = pd.read_csv(path_to_folder + \"train.tsv\",  sep='\\t')\n","# Take look at the structure.\n","train_df.head()\n","\n","# We will take off some images from the training process.\n","bananas = [66, 425, 751, 758, 913, 1517, 1555, 1633, 2175, 2860, 3116, 3473, 4104, 4713, 4862, 4983, 5416, 5431, 5436, 5671, 5690, 6106, 7022, 7141, 7154]\n","aspags = [599,1300,2595]\n","potatos = [91, 131, 1184, 2998, 3373, 3397, 3653, 4599, 5718, 5918, 6646]\n","pudding = [734,1059,1203,1252,1788,2028,2161,2310,2597,2633,3448,3629,4151,4879,4928,5064,5662,5771,5970,5973,7016]\n","poultry = [200,2147,2337,2606,3003,5602,6932]\n","salad = [1519,1778,3088,3190,4609,5430,6707,6921,7127]\n","fresh_bread= [1405,1967,2775,3606]\n","fresh_herbs= [1419,3737]\n","pork = [699,982,3451,4408,5146,5644,5936,7057]\n","minced_meat = [2842,2920,3911,4442,5119,5405,5721,6607,7214]\n","nectarine = [839,1018,1465,2051,2773,3294,3295,3340,4679,5887,6735,6909]\n","kiwis = [183,477,501,681,2106,2348,3660,4090,4277,5538,6854]\n","lunch_deli = [730,1506,3024,3909,4101,5498]\n","milk = [1779,1854,2784,3797,4849,6910]\n","eggs = [2403,2729,2755,4946,4949,5200,5248,5908,6346,6665]\n","fish = [19,57,1685,2428,4992,6137,4748]\n","onion = [1490,2327,3231,6075,4127,5606,6208]\n","broccli = [395,1044,1317,1420,11575,2561,2929,3741,3945,4488,4902,5616,5643,5666,7028]\n","cheese = [1009,1026,4782,4892,5024,5133,5365,6394]\n","citrus = [183,560,694,2274,6050]\n","cucumber = [1135,1401,1865,2137,2386,3019,3558,3624,3740,3850,4097,4119,4206,4305,4319,4349,5179,5480,6272,6307]\n","pinapls = [573,1866,3885,5585,7048,7225]\n","prepacked_bread = [52,406,520,3535,4540,5219,5432,5847,6705,6882,7085]\n","bell = [128,276,388,1740,3285,5150,5915,6069,6114,6376,7017]\n","berries = [1379,1482,1725,2817,2883,3695,5094,5342,5401,5550,5635,6220]\n","\n","# making them in one big list.\n","all_ = bananas + aspags + potatos + pudding + poultry + salad + fresh_bread + fresh_herbs + pork + minced_meat + nectarine + kiwis + lunch_deli + milk + eggs + fish + onion+ broccli +cheese+citrus+cucumber+pinapls+prepacked_bread+bell+berries\n","\n","# searching their index in the dataframe.\n","serie = train_df['file'].values\n","index = []\n","for i, value in enumerate(serie):\n","    for j in all_:\n","        a = r\"^\"+str(j)+\"\\..\"        \n","        if re.match(a,value):\n","            index.append(i)\n","            \n","# deleting files from the data frame.\n","train_df_new = train_df.drop(index)\n","\n","print(\"The New Number of Images is : {}\".format(len(train_df_new)))\n","print(\"The Past Number of Images is : {}\".format(len(train_df)))\n","\n","# getting the count of each class\n","label_counts = train_df_new.label.value_counts()\n","plt.figure(figsize = (12,6))\n","sns.barplot(label_counts.index, label_counts.values, alpha = 0.9)\n","plt.xticks(rotation = 'vertical')\n","plt.xlabel('Image Labels', fontsize =12)\n","plt.ylabel('Counts', fontsize = 12)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FlE3P_J9U06F","colab_type":"text"},"source":["**MODEL PREPARATION**"]},{"cell_type":"code","metadata":{"id":"6N0bcuatVGc_","colab_type":"code","colab":{}},"source":["# Defining The Model, Batch Size, size of the Images and path where the training Images are.\n","MODEL= densenet161\n","BATCH = 32\n","SIZE = 224\n","pathTrain = Path(\"gdrive/My Drive/train/\")\n","\n","# Loading The Images \n","\n","# defining Transformations for Image Augmentation.\n","tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=300)\n","\n","# Making Objet to hold all the images of training and validation, be sure to normalize them using imagenet stats.\n","data = ImageDataBunch.from_df(pathTrain, train_df_new, size= SIZE, bs = BATCH, ds_tfms = tfms, valid_pct = 0.0).normalize(imagenet_stats)\n","\n","# show sample of images.\n","data.show_batch(rows=3, figsize=(12,12))\n","\n","# Model Preparation\n","\n","from sklearn.metrics import f1_score\n","\n","# Making Function to use it in metrics for the CNN.\n","def f1_macro_score(y_pred, y_true, tens=True):\n","    score = f1_score(y_true, np.argmax(y_pred, axis = 1), average = 'macro')\n","    if tens:\n","        score= tensor(score)\n","    else:\n","        score= score\n","    return score\n","\n","# Function to calculate the F1-Score for validation data using Confusion Matrix.\n","def f1_from_cm(cm):\n","    TP = np.diag(cm)\n","    FP = np.sum(cm, axis=0) - TP\n","    FN = np.sum(cm, axis=1) - TP\n","    num_classes = 25\n","    TN = []\n","    for i in range(num_classes):\n","      temp = np.delete(cm, i, 0)\n","      temp = np.delete(temp, i, 1)\n","      TN.append(sum(sum(temp)))\n","    precision = TP/(TP+FP)\n","    recall = TP/(TP+FN)\n","    F1 = 2 * (precision.mean() * recall.mean()) / (precision.mean() + recall.mean())\n","    return F1\n","\n","def performane_indiators(model):\n","    # Plotting some curves to see the performance.\n","    model.recorder.plot_losses()\n","    model.recorder.plot_metrics()\n","    model.recorder.plot()\n","    \n","    # Print confusion matrix, F1 score and top losses.\n","    result = ClassificationInterpretation.from_learner(model)\n","    result.plot_top_losses(9, figsize=(15,15) , heatmap = False)\n","    result.plot_confusion_matrix(figsize=(12,12), dpi = 50)\n","    print(\"F1-Score for validation is {}\".format(f1_from_cm(result.confusion_matrix())))\n","\n","# Making The CNN Model Using Our Images And Densenet161 Architeture.\n","model = cnn_learner(data, MODEL, metrics=[accuracy])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9TQ35mOBVMQY","colab_type":"text"},"source":["**TRAINING**"]},{"cell_type":"code","metadata":{"id":"ZIMvorZdT2uQ","colab_type":"code","colab":{}},"source":["# Model Training\n","\n","# Fitting the model to data using OneCycle Policy.\n","model.fit_one_cycle(20)\n","\n","# show results.\n","performane_indiators(model)\n","\n","model.save('stage-one')\n","\n","# unfreeze the model to train top layers.\n","model.unfreeze()\n","# Fitting the unfrozzen model to data using OneCycle Policy.\n","model.fit_one_cycle(15)\n","\n","# show result.\n","performane_indiators(model)\n","\n","model.save('stage-two')\n","\n","# Exporting Model\n","\n","# we will export the model which got the best result on validation set.\n","# in my case, the best was the stage-one.\n","model.load('stage-one')\n","model.export('densenet161_best_so_far.pkl')\n","\n","print(\"Saved to path: {}\".format(model.path))"],"execution_count":0,"outputs":[]}]}